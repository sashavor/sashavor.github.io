---
permalink: /
excerpt: "About me"
title : "Sasha Luccioni"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a Research Scientist at [HuggingFace](https://huggingface.co/){:target="_blank"}, where I work on the ethical and societal impacts of Machine Learning models and datasets. 

I am also a founding member of [Climate Change AI (CCAI)](https://www.climatechange.ai/){:target="_blank"}, an organization which catalyzes impactful work applying machine learning to the climate crisis and a member of the board of directors of [Women in Machine Learning (WiML)](wimlworkshop.org/){:target="_blank"} and one of the Ethical Review chairs of [NeurIPS 2022](neurips.cc/){:target="_blank"}.

My goal in research is to contribute towards understanding the carbon footprint of AI algorithms, ranging from the manufacturing of the hardware used for training AI models to the energy costs and carbon emissions of deploying AI models in practice.

You can contact me at: sasha.luccioni(at)huggingface.co

Updates
======
* I am co-lead organizer of the [Tackling Climate Change with Machine Learning workshop](https://www.climatechange.ai/events/iclr2023){:target="_blank"} at the [2023 ICLR conference](https://iclr.cc/){:target="_blank"} taking place in Kigali Rwanda.
* I was an Ethics Review Chair of [NeurIPS 2022](https://neurips.cc/){:target="_blank"}.
* I joined the [WiML](https://wimlworkshop.org/) Board of Directors in Spring 2022.
* I was a Senior Area Chair on the Efficient NLP track of [NAACL 2022](https://2022.naacl.org/){:target="_blank"}.

Recent News Coverage
=============
* My work on calculating the carbon footprint of BLOOM, a large language model, was featured in [MIT Technology Review (Nov 2022)](https://www.technologyreview.com/2022/11/14/1063192/were-getting-a-better-idea-of-ais-true-carbon-footprint){:target="_blank"}.
* The [Stable Diffusion Bias Explorer](Researchers Find Stable Diffusion Amplifies Stereotypes) tool was featured in [Tech Policy Press](https://techpolicy.press/researchers-find-stable-diffusion-amplifies-stereotypes/) and [VICE](https://www.vice.com/en/article/bvm35w/this-tool-lets-anyone-see-the-bias-in-ai-image-generators)
* I was featured in a [recent CBC article](https://www.cbc.ca/news/science/artificial-intelligence-racism-bias-1.6027150) about the dangers of bias in AI models.

About me
======

The research subjects I am working on are:
* The societal and environmental impacts of artificial intelligence (AI)
* Calculating the carbon impact of AI algorithms
* Ethical and explainable machine learning
* Best practices for data collection and sharing

Check out the other pages on this site for more information about my [publications](https://sashavor.github.io/publications/), my [biography](https://sashavor.github.io/biography/) [talks](https://sashavor.github.io/talks/) I have given and [projects](https://sashavor.github.io/projects/) that I'm involved in.

For my full CV, see [here](https://sashavor.github.io/cv/)

